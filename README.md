НГ Hack 2019
============

Материалы к хакатону по обработке естественного языка (NLP) НГ Hack 2019.

[Страница соревнования](https://datasouls.com/c/nghack2019/)


## Задачи

### 1. Классификация интентов (`intent`)

Доступные данные:
- `data/intent_train.csv` — примеры для обучения, колонка `text` содержит текст сообщения, `label` — название интента
- `data/intent_check.csv` — пример входного тестового файла

Решению необходимо для всех тестовых примеров определить интент. На выходе должен быть файл с колонками `id` (идентификатор примера из входного файла), `label` (название интента).

Метрика качества: Multi-class F1 Macro-average (описание в [scikit-learn docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html))

### 2. Исправление орфографических ошибок (`grammar`)

Доступные данные:
- `data/grammar_train.csv` — примеры для обучения, колонки:
    - `id` — идентификатор примера
    - `sentence_with_a_mistake` — исходное предложение
    - `correct_sentence` — корректная версия предложения
    - `mistake_type` — тип допущенной ошибки
- `data/grammar_check.csv` — пример входного тестового файла (содержит только исходное предложение)

Решению необходимо для всех тестовых примеров исправить ошибки и записать корректную (исправленную) версию. На выходе должен быть файл с колонками `id` и `correct_sentence`.

Метрика качества — **F1**:
- По всем тестовым примерам подсчитываются счетчики TP, FP, FN:
  - если исправление совпадает с тем, что в правильном ответе, то TP += 1
  - если исправление не совпадает с тем, что в правильном ответе, но совпадает с исходным предложением, которое подавалось на вход, то FN += 2
  - иначе FP += 30
- Метрика F1 вычисляется по формуле: 
  - `F1 = 2*(precision*recall)/(precision+recall)`
  - `precision = TP / (TP + FP)`
  - `recall = TP / (TP + FN)`
 

### 3. Предсказание оценки в чате с поддержкой (`support`)

Доступные данные:
- `data/support_train.csv` — примеры для обучения, колонка `text` содержит текст сообщения, `label` — метку класса (`positive`, `neutral` или `negative`)
- `data/support_check.csv` — пример входного тестового файла (не содержит колонку `label`)

Решению необходимо для всех тестовых примеров определить метку класса. На выходе должен быть файл с колонками `id` (идентификатор примера из входного файла), `label` (метка класса).

Метрика качества: Multi-class F1 Macro-average (описание в [scikit-learn docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html))Метрика


### 4. Обнаружение фальсификаций в телефонной статистике (`callcenter`)

Доступные данные:
- `data/callcenter_train.csv` — примеры для обучения, содержит колонку `Метка` (1 — есть подмена, 0 — нет подмены)
- `data/callcenter_before.csv` — как выглядели данные из `train` до подмены
- `data/callcenter_check.csv` — пример входного тестового файла (не содержит колонку `Метка`)

Решению необходимо для входного журнала обращений в техподдержку выявить подмены в записях, в колонке `Метка` записать индикатор подмены.

Метрика качества: [F1 Score](https://en.wikipedia.org/wiki/F1_score)


## Формат решения

В проверяющую систему необходимо отправить код решений, запакованный в ZIP-архив. Решения запускаются в изолированном окружении при помощи [Docker](https://www.docker.com/), время и ресурсы для тестирования ограничены. В простом случае, участнику нет необходимости разбираться с технологией Docker.

Пример оформления решения находится в каталоге [`solution`](solution).

В корне архива обязательно должен быть файл `metadata.json` следующего содержания:

```json
{
    "image": "datasouls/python",
    "entry_points": {
        "intent": "python intent.py {input_csv} {output_csv}",
        "grammar": "python grammar.py {input_csv} {output_csv}",
        "support": "python support.py {input_csv} {output_csv}",
        "callcenter": "python callcenter.py {input_csv} {output_csv}"
    }
}
```

Здесь `image` — поле с названием docker-образа, в котором будет запускаться решение, `entry_points` — команды, при помощи которых запускаются соответствующие решения. Для решения текущей директорией будет являться корень архива. 

Не обязательно решать все четыре задачи. Решение будет протестировано только на тех задачах, для которых указаны `entry_points`.

В командах необходимо использовать шаблоны, в которые при запуске в тестирующей системе будут подставлены необходимые значения: 
- `{input_csv}` — путь к входному CSV-файлу с тестовыми данными
- `{output_csv}` — путь к CSV-файлу с колонками `id` и целевой переменной


## Ограничения

Контейнер с решением запускается в следующих условиях:

- решению доступны ресурсы
  - **4 Гб** оперативной памяти
  - 2 vCPU
- лимит времени одного запуска решения: 20 сек
- решение не имеет доступа к ресурсам интернета
- максимальный размер упакованного и распакованного архива с решением: **2 Гб**
